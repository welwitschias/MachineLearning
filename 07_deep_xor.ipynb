{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bbebcd5-f167-459c-bd11-bb5b1db0c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74254ed0-e560-4daa-87b7-fa65e2fa4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b61697f-41ab-44b7-a2df-3e58eebf353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e2d29a-9d0b-41c5-86e7-1deb5fd88b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, x_data, t_data):\n",
    "        self.name = gate_name\n",
    "        self.__x_data = x_data\n",
    "        self.__t_data = t_data\n",
    "        \n",
    "        self.__x_data = x_data.reshape(4, 2)\n",
    "        self.__t_data = t_data.reshape(4, 1)\n",
    "\n",
    "        self.__W2 = np.random.rand(2, 6)\n",
    "        self.__b2 = np.random.rand(1)\n",
    "        \n",
    "        self.__W3 = np.random.rand(6, 1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "        self.__learning_rate = 1e-2\n",
    "        \n",
    "    def feed_forward(self):\n",
    "        delta = 1e-7\n",
    "        z2 = np.dot(self.__x_data, self.__W2) + self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\n",
    "        y = sigmoid(z3)\n",
    "\n",
    "        return -np.sum(self.__t_data * np.log(y + delta) + (1 - self.__t_data) * np.log((1-y) + delta))\n",
    "\n",
    "    def train(self):\n",
    "        def f(x): return self.feed_forward()\n",
    "\n",
    "        print(\"initial loss func =\", self.feed_forward())\n",
    "\n",
    "        for step in range(10001):\n",
    "            self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
    "            self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
    "\n",
    "            self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
    "            self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
    "            \n",
    "            if step % 500 == 0:\n",
    "                print(\"step =\", step, \", loss value =\", self.feed_forward())\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        z2 = np.dot(x_data, self.__W2) + self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "\n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\n",
    "        y = sigmoid(z3)\n",
    "        \n",
    "        if y >= 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "\n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d54817-2c21-4fb2-b23f-9dccbd4f528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss func = 6.8921416799761035\n",
      "step = 0 , loss value = 6.638136686587217\n",
      "step = 500 , loss value = 2.122003630649658\n",
      "step = 1000 , loss value = 1.7992006827031632\n",
      "step = 1500 , loss value = 1.3854289932577442\n",
      "step = 2000 , loss value = 0.9859317932800722\n",
      "step = 2500 , loss value = 0.6770003797381886\n",
      "step = 3000 , loss value = 0.472147339618912\n",
      "step = 3500 , loss value = 0.3429628419791183\n",
      "step = 4000 , loss value = 0.2603060699084463\n",
      "step = 4500 , loss value = 0.20533664806070528\n",
      "step = 5000 , loss value = 0.16719293563585524\n",
      "step = 5500 , loss value = 0.13966876647037524\n",
      "step = 6000 , loss value = 0.11912190690971304\n",
      "step = 6500 , loss value = 0.10333419247162731\n",
      "step = 7000 , loss value = 0.09090257089730819\n",
      "step = 7500 , loss value = 0.08090758697093449\n",
      "step = 8000 , loss value = 0.07272713454824525\n",
      "step = 8500 , loss value = 0.06592815000896042\n",
      "step = 9000 , loss value = 0.060201469857677284\n",
      "step = 9500 , loss value = 0.0553213942109791\n",
      "step = 10000 , loss value = 0.05111984919931553\n"
     ]
    }
   ],
   "source": [
    "# AND_GATE training\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t_data = np.array([0, 0, 0, 1])\n",
    "\n",
    "AND_obj = LogicGate(\"AND_GATE\", x_data, t_data)\n",
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1835f699-a474-4995-95be-6c5a39f5f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND_GATE\n",
      "[0 0] = 0\n",
      "[0 1] = 0\n",
      "[1 0] = 0\n",
      "[1 1] = 1\n"
     ]
    }
   ],
   "source": [
    "# AND_GATE prediction\n",
    "print(AND_obj.name)\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "    print(input_data, \"=\", logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a2d4cd-5d85-448d-af2f-72ef7c44b4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss func = 2.5736240688083516\n",
      "step = 0 , loss value = 2.553904591789582\n",
      "step = 500 , loss value = 1.8163871425057525\n",
      "step = 1000 , loss value = 1.3269563362197065\n",
      "step = 1500 , loss value = 0.9091399498074608\n",
      "step = 2000 , loss value = 0.620062739169588\n",
      "step = 2500 , loss value = 0.43629398795789565\n",
      "step = 3000 , loss value = 0.321233635712679\n",
      "step = 3500 , loss value = 0.24709697854888868\n",
      "step = 4000 , loss value = 0.19722741364278912\n",
      "step = 4500 , loss value = 0.1622060596299467\n",
      "step = 5000 , loss value = 0.13665132975783564\n",
      "step = 5500 , loss value = 0.117382957463823\n",
      "step = 6000 , loss value = 0.1024462115417755\n",
      "step = 6500 , loss value = 0.09059273151666945\n",
      "step = 7000 , loss value = 0.08099682040926921\n",
      "step = 7500 , loss value = 0.07309495668064245\n",
      "step = 8000 , loss value = 0.06649172421772376\n",
      "step = 8500 , loss value = 0.060902772324592125\n",
      "step = 9000 , loss value = 0.05611912877921397\n",
      "step = 9500 , loss value = 0.05198422597956714\n",
      "step = 10000 , loss value = 0.048378723816964654\n"
     ]
    }
   ],
   "source": [
    "# OR_GATE training\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t_data = np.array([0, 1, 1, 1])\n",
    "\n",
    "OR_obj = LogicGate(\"OR_GATE\", x_data, t_data)\n",
    "OR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f968874d-eff1-4235-8207-f00d810b92fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR_GATE\n",
      "[0 0] = 0\n",
      "[0 1] = 1\n",
      "[1 0] = 1\n",
      "[1 1] = 1\n"
     ]
    }
   ],
   "source": [
    "# OR_GATE prediction\n",
    "print(OR_obj.name)\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = OR_obj.predict(input_data)\n",
    "    print(input_data, \"=\", logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a14864-a10f-4f12-8971-1012e28697f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss func = 2.4676112844954963\n",
      "step = 0 , loss value = 2.4588062928656216\n",
      "step = 500 , loss value = 2.250023919780351\n",
      "step = 1000 , loss value = 2.1982212699511727\n",
      "step = 1500 , loss value = 2.0816434380013273\n",
      "step = 2000 , loss value = 1.8136988295124887\n",
      "step = 2500 , loss value = 1.5275279761491594\n",
      "step = 3000 , loss value = 1.3063314810004834\n",
      "step = 3500 , loss value = 1.1126124222612923\n",
      "step = 4000 , loss value = 0.9028567378197747\n",
      "step = 4500 , loss value = 0.6874845001771053\n",
      "step = 5000 , loss value = 0.5075438962568583\n",
      "step = 5500 , loss value = 0.37737417381923377\n",
      "step = 6000 , loss value = 0.288071626574969\n",
      "step = 6500 , loss value = 0.22675927792920741\n",
      "step = 7000 , loss value = 0.1836780992467966\n",
      "step = 7500 , loss value = 0.1524998516507617\n",
      "step = 8000 , loss value = 0.1292658059423828\n",
      "step = 8500 , loss value = 0.11148371941026586\n",
      "step = 9000 , loss value = 0.097550122764119\n",
      "step = 9500 , loss value = 0.08640570341132814\n",
      "step = 10000 , loss value = 0.07733160305072581\n"
     ]
    }
   ],
   "source": [
    "# NAND_GATE training\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t_data = np.array([1, 1, 1, 0])\n",
    "\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", x_data, t_data)\n",
    "NAND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8204a57a-b961-499d-92ab-fb36958b8af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND_GATE\n",
      "[0 0] = 1\n",
      "[0 1] = 1\n",
      "[1 0] = 1\n",
      "[1 1] = 0\n"
     ]
    }
   ],
   "source": [
    "# NAND_GATE prediction\n",
    "print(NAND_obj.name)\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = NAND_obj.predict(input_data)\n",
    "    print(input_data, \"=\", logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d47a58d-c3c6-4c28-90f9-51ad1d0af1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss func = 6.502088595830207\n",
      "step = 0 , loss value = 6.34800729308086\n",
      "step = 500 , loss value = 2.7766392577161803\n",
      "step = 1000 , loss value = 2.774246215248463\n",
      "step = 1500 , loss value = 2.7723683093527622\n",
      "step = 2000 , loss value = 2.7705801772684104\n",
      "step = 2500 , loss value = 2.7685370892096937\n",
      "step = 3000 , loss value = 2.765847872444026\n",
      "step = 3500 , loss value = 2.7619452176434263\n",
      "step = 4000 , loss value = 2.7559106999639758\n",
      "step = 4500 , loss value = 2.7462369931951036\n",
      "step = 5000 , loss value = 2.730567866894572\n",
      "step = 5500 , loss value = 2.7054954414632038\n",
      "step = 6000 , loss value = 2.666326534636145\n",
      "step = 6500 , loss value = 2.606602710741814\n",
      "step = 7000 , loss value = 2.518225794485091\n",
      "step = 7500 , loss value = 2.3943190637494487\n",
      "step = 8000 , loss value = 2.232272142594065\n",
      "step = 8500 , loss value = 2.0293607342026947\n",
      "step = 9000 , loss value = 1.7803589707398857\n",
      "step = 9500 , loss value = 1.4926521501738552\n",
      "step = 10000 , loss value = 1.2006919463426529\n"
     ]
    }
   ],
   "source": [
    "# XOR_GATE training\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t_data = np.array([0, 1, 1, 0])\n",
    "\n",
    "XOR_obj = LogicGate(\"XOR_GATE\", x_data, t_data)\n",
    "XOR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231f844f-4f60-4633-94a5-d0ab993597b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR_GATE\n",
      "[0 0] = 0\n",
      "[0 1] = 1\n",
      "[1 0] = 1\n",
      "[1 1] = 0\n"
     ]
    }
   ],
   "source": [
    "# XOR_GATE prediction\n",
    "print(XOR_obj.name)\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = XOR_obj.predict(input_data)\n",
    "    print(input_data, \"=\", logical_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
